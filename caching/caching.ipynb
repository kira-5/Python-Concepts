{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://hackernoon.com/caches-in-python\n",
    "# https://www.scaler.com/topics/python-cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dictionary-Based Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty cache dictionary\n",
    "cache = {}\n",
    "\n",
    "# Function to calculate the factorial of a number\n",
    "def factorial(n):\n",
    "    if n in cache:\n",
    "        print(f\"cache:: {cache}\")\n",
    "        return cache[n]  # Return cached result if available\n",
    "\n",
    "    # Calculate factorial if not cached\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "\n",
    "    # Cache the result\n",
    "    cache[n] = result\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "print(factorial(5))  # Calculates and caches factorial of 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Using Decorators\n",
    "\n",
    "def memoize(func):\n",
    "    cache = {}\n",
    "\n",
    "    def memoized_func(*args):\n",
    "        if args not in cache:\n",
    "            cache[args] = func(*args)\n",
    "        return cache[args]\n",
    "\n",
    "    return memoized_func\n",
    "\n",
    "\n",
    "@memoize\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "\n",
    "print(factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### JSON-Based Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 120, 'time': '2024-04-02 23:04:17.824119'}\n"
     ]
    }
   ],
   "source": [
    "# Using Decorators\n",
    "\n",
    "import json\n",
    "\n",
    "def memoize(func):\n",
    "    cache_file = 'cache.json'\n",
    "\n",
    "    try:\n",
    "        with open(cache_file, 'r') as f:\n",
    "            cache = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        cache = {}\n",
    "\n",
    "    def memoized_func(*args):\n",
    "        key = str(args[0])\n",
    "        if key not in cache:\n",
    "            result = func(*args)\n",
    "            cache[key] = result\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache, f)\n",
    "        return cache[key]\n",
    "\n",
    "    return memoized_func\n",
    "\n",
    "\n",
    "\n",
    "@memoize\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "\n",
    "print(factorial(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# Using Decorators\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "def memoize(func=None, maxsize=None, typed=None, ttl=None):\n",
    "    cache_file = 'cache.json'\n",
    "\n",
    "    try:\n",
    "        with open(cache_file, 'r') as f:\n",
    "            cache = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        cache = {}\n",
    "\n",
    "    def memoized_func(*args, **kwargs):\n",
    "        # key = args if typed else (args, frozenset(kwargs.items()))\n",
    "        key = str(args[0])\n",
    "        # key = str(key)  # Convert to string for key\n",
    "        if key not in cache:\n",
    "            result = func(*args, **kwargs)\n",
    "            cache[key] = {'result': result, 'time': str(datetime.now())}\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache, f)\n",
    "        elif ttl and datetime.now() - cache[key]['time'] > timedelta(seconds=ttl):\n",
    "            del cache[key]\n",
    "            result = func(*args, **kwargs)\n",
    "            cache[key] = {'result': result, 'time': str(datetime.now())}\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(cache, f)\n",
    "        return cache[key]['result']\n",
    "\n",
    "    return memoized_func\n",
    "\n",
    "\n",
    "\n",
    "@memoize\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "\n",
    "print(factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functools LRU Cache\n",
    "- It is part of the Python standard library, so no external installation is required.\n",
    "- -It supports caching with a maximum size limit, eviction of least recently used entries, and memoization of function results.\n",
    "- - It is easy to use and integrates well with existing functions via decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "CacheInfo(hits=0, misses=6, maxsize=128, currsize=6)\n",
      "{'maxsize': 128, 'typed': False}\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "# With typed=True, you can now set the expiration time using the ttl (time to live) argument\n",
    "\n",
    "@lru_cache(maxsize=128, typed=False)\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial.cache_info())\n",
    "print(factorial.cache_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To implement TTL (Time To Live) for caching with functools.lru_cache, you'll need to customize the caching mechanism slightly. \n",
    "- Unfortunately, the functools.lru_cache decorator does not directly support TTL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "CacheInfo(hits=6, misses=6, maxsize=6, currsize=6)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "def lru_cache_with_ttl(maxsize=128, typed=False, ttl=None):\n",
    "    def decorator(func):\n",
    "        cache = functools.lru_cache(maxsize=maxsize, typed=typed)\n",
    "\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            key = args + tuple(kwargs.items())\n",
    "            if key in wrapper.cache:\n",
    "                value, timestamp = wrapper.cache[key]\n",
    "                if ttl and time.time() > timestamp:\n",
    "                    del wrapper.cache[key]\n",
    "                else:\n",
    "                    return value\n",
    "\n",
    "            result = func(*args, **kwargs)\n",
    "            wrapper.cache[key] = (result, time.time() + ttl) if ttl else result\n",
    "            return result\n",
    "\n",
    "        def cache_info():\n",
    "            hits = misses = maxsize = currsize = len(wrapper.cache)\n",
    "            return functools._CacheInfo(hits, misses, maxsize, currsize)\n",
    "\n",
    "        def cache_clear():\n",
    "            wrapper.cache.clear()\n",
    "\n",
    "        wrapper.cache_info = cache_info\n",
    "        wrapper.cache_clear = cache_clear\n",
    "        wrapper.cache = {}\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "@lru_cache_with_ttl(maxsize=128, typed=False, ttl=5)  # Set TTL to 5 seconds\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial.cache_info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functools cache\n",
    "- Returns the same as lru_cache(maxsize=None), creating a thin wrapper around a dictionary lookup for the function arguments. Because it never needs to evict old values, this is smaller and faster than lru_cache() with a size limit.\n",
    "-  It's designed to provide a simple and efficient caching mechanism, but without built-in support for expiration policies.\n",
    "-  Work only in above python version of 3.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628800\n",
      "120\n",
      "479001600\n",
      "CacheInfo(hits=0, misses=0, maxsize=None, currsize=0)\n"
     ]
    }
   ],
   "source": [
    "from functools import cache\n",
    "\n",
    "@cache\n",
    "def factorial_1(n):\n",
    "    return n * factorial(n-1) if n else 1\n",
    "\n",
    "\n",
    "print(factorial(10))      # no previously cached result, makes 11 recursive calls\n",
    "print(factorial(5))       # just looks up cached value result\n",
    "print(factorial(12))      # makes two new recursive calls, the other 10 \n",
    "\n",
    "print(factorial_1.cache_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  can implement a custom caching decorator that adds TTL functionality similar to what we did with functools.lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "CacheInfo(hits=6, misses=6, maxsize=None, currsize=None)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "def cache_with_ttl(ttl=None):\n",
    "    cache = {}\n",
    "\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            key = args + tuple(kwargs.items())\n",
    "            if key in cache:\n",
    "                value, timestamp = cache[key]\n",
    "                if ttl and time.time() > timestamp:\n",
    "                    del cache[key]\n",
    "                else:\n",
    "                    return value\n",
    "\n",
    "            result = func(*args, **kwargs)\n",
    "            cache[key] = (result, time.time() + ttl) if ttl else result\n",
    "            return result\n",
    "\n",
    "        def cache_info():\n",
    "            hits = misses = len(cache)\n",
    "            return functools._CacheInfo(hits, misses, None, None)\n",
    "\n",
    "        def cache_clear():\n",
    "            cache.clear()\n",
    "\n",
    "        wrapper.cache_info = cache_info\n",
    "        wrapper.cache_clear = cache_clear\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator\n",
    "\n",
    "@cache_with_ttl(ttl=60)  # Set TTL to 60 seconds\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial.cache_info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Cache Classes\n",
    "- For more control over caching behavior, you can create custom cache classes that implement specific caching strategies, such as FIFO (First-In-First-Out), LRU, or LFU (Least Frequently Used). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.cache = OrderedDict()\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            value = self.cache.pop(key)\n",
    "            self.cache[key] = value  # Move the item to the end to mark it as most recently used\n",
    "            return value\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def put(self, key, value):\n",
    "        if key in self.cache:\n",
    "            self.cache.pop(key)\n",
    "        elif len(self.cache) >= self.max_size:\n",
    "            self.cache.popitem(last=False)  # Remove the least recently used item\n",
    "        self.cache[key] = value\n",
    "\n",
    "def factorial(n, cache):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    if n in cache.cache:  # Access the cache dictionary inside the LRUCache instance\n",
    "        return cache.get(n)\n",
    "    result = n * factorial(n - 1, cache)\n",
    "    cache.put(n, result)  # Store the result in the cache\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "cache = LRUCache(5)  # You can adjust the cache size as per your requirements\n",
    "n = 5\n",
    "print(factorial(n, cache))  # Output: 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To add caching expiration, you would need to introduce additional logic to track the time each item was added to the cache and implement a mechanism to remove items that have exceeded their expiration time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "class LRUCache:\n",
    "    def __init__(self, max_size, expiration_time):\n",
    "        self.max_size = max_size\n",
    "        self.expiration_time = expiration_time\n",
    "        self.cache = OrderedDict()\n",
    "        self.timestamps = {}\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.cache:\n",
    "            if time.time() - self.timestamps[key] <= self.expiration_time:\n",
    "                value = self.cache.pop(key)\n",
    "                self.cache[key] = value  # Move the item to the end to mark it as most recently used\n",
    "                self.timestamps[key] = time.time()\n",
    "                return value\n",
    "            else:\n",
    "                # Expired, remove from cache\n",
    "                del self.cache[key]\n",
    "                del self.timestamps[key]\n",
    "        return None\n",
    "\n",
    "    def put(self, key, value):\n",
    "        current_time = time.time()\n",
    "        if key in self.cache:\n",
    "            self.cache.pop(key)\n",
    "            del self.timestamps[key]\n",
    "        elif len(self.cache) >= self.max_size:\n",
    "            # Remove the least recently used item\n",
    "            oldest_key = next(iter(self.cache))\n",
    "            del self.cache[oldest_key]\n",
    "            del self.timestamps[oldest_key]\n",
    "        self.cache[key] = value\n",
    "        self.timestamps[key] = current_time\n",
    "\n",
    "\n",
    "\n",
    "def factorial(n, cache):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    if n in cache.cache:  # Access the cache dictionary inside the LRUCache instance\n",
    "        return cache.get(n)\n",
    "    result = n * factorial(n - 1, cache)\n",
    "    cache.put(n, result)  # Store the result in the cache\n",
    "    return result\n",
    "\n",
    "# Example usage:\n",
    "cache = LRUCache(5, expiration_time=60)  # Cache size is 5 and expiration time is 60 seconds\n",
    "n = 5\n",
    "print(factorial(n, cache))  # Output: 120\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third-Party Libraries\n",
    "- cachetools, redis, memcached\n",
    "- These libraries offer more advanced features and support distributed caching, persistent storage, and scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### cachetools\n",
    "- cachetools is a third-party library providing various caching utilities, including LRUCache, TTLCache, LFUCache, and others. \n",
    "- It is not part of the Python standard library and needs to be installed separately (pip install cachetools).\n",
    "- It offers more advanced caching algorithms and configurations compared to functools.lru_cache\n",
    "  -  For example, it provides different cache implementations such as TTL (time-to-live) cache and LFU (Least Frequently Used) cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cachetools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcachetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached, TTLCache\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define a TTLCache with a maximum size of 128 and TTL of 60 seconds\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cache \u001b[38;5;241m=\u001b[39m TTLCache(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, ttl\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cachetools'"
     ]
    }
   ],
   "source": [
    "from cachetools import cached, TTLCache\n",
    "\n",
    "# Define a TTLCache with a maximum size of 128 and TTL of 60 seconds\n",
    "cache = TTLCache(maxsize=128, ttl=60)\n",
    "\n",
    "# Decorate a function to use the cache\n",
    "@cached(cache)\n",
    "def factorial(n):\n",
    "    return 1 if n == 0 else n * factorial(n - 1)\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial(4))  # Retrieves the cached result\n",
    "print(factorial(6))  # Calls the function and caches the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Redis\n",
    "- Redis is an in-memory data structure store used as a database, cache, and message broker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'redis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mredis\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Connect to Redis\u001b[39;00m\n\u001b[0;32m      4\u001b[0m redis_client \u001b[38;5;241m=\u001b[39m redis\u001b[38;5;241m.\u001b[39mRedis(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6379\u001b[39m, db\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'redis'"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "# Connect to Redis\n",
    "redis_client = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "# Define a function to use Redis as a cache\n",
    "def factorial(n):\n",
    "    cached_result = redis_client.get(f'factorial:{n}')\n",
    "    if cached_result:\n",
    "        return int(cached_result)\n",
    "    result = 1 if n == 0 else n * factorial(n - 1)\n",
    "    redis_client.set(f'factorial:{n}', result)\n",
    "    return result\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial(4))  # Retrieves the cached result\n",
    "print(factorial(6))  # Calls the function and caches the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Memcached\n",
    "- Memcached is a high-performance, distributed memory object caching system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymemcache'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymemcache\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Connect to Memcached\u001b[39;00m\n\u001b[0;32m      4\u001b[0m memcached_client \u001b[38;5;241m=\u001b[39m Client((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m11211\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymemcache'"
     ]
    }
   ],
   "source": [
    "from pymemcache.client.base import Client\n",
    "\n",
    "# Connect to Memcached\n",
    "memcached_client = Client(('localhost', 11211))\n",
    "\n",
    "# Define a function to use Memcached as a cache\n",
    "def factorial(n):\n",
    "    cached_result = memcached_client.get(f'factorial:{n}')\n",
    "    if cached_result:\n",
    "        return int(cached_result.decode())\n",
    "    result = 1 if n == 0 else n * factorial(n - 1)\n",
    "    memcached_client.set(f'factorial:{n}', str(result))\n",
    "    return result\n",
    "\n",
    "# Test the cached factorial function\n",
    "print(factorial(5))  # Calls the function and caches the result\n",
    "print(factorial(4))  # Retrieves the cached result\n",
    "print(factorial(6))  # Calls the function and caches the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without LRU Cache\n",
    "import time\n",
    "start_time = time.time_ns()\n",
    "factorial(50)\n",
    "print(time.time_ns() - start_time)\n",
    "\n",
    "\n",
    "# With LRU Cache\n",
    "start_time = time.time_ns()\n",
    "factorial_lru_cache(50)\n",
    "print(time.time_ns() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "fibonacci(40)\n",
    "end_time = time.time()\n",
    "execution_time_without_cache = end_time - start_time\n",
    "print(\"Time taken without cache: {:.8f} seconds\".format(execution_time_without_cache))\n",
    "\n",
    "start_time = time.time()\n",
    "fibonacci(40)\n",
    "end_time = time.time()\n",
    "execution_time_with_cache = end_time - start_time\n",
    "print(\"Time taken with cache: {:.8f} seconds\".format(execution_time_with_cache))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-python3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
